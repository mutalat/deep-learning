{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "base_dir = \"medical_dataset\"\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "val_dir = os.path.join(base_dir, \"val\")\n",
        "test_dir = os.path.join(base_dir, \"test\")\n",
        "\n",
        "classes = [\"DISEASE\", \"HEALTHY\"]\n",
        "\n",
        "for folder in [train_dir, val_dir, test_dir]:\n",
        "    for cls in classes:\n",
        "        os.makedirs(os.path.join(folder, cls), exist_ok=True)\n",
        "\n",
        "def generate_images(path, num):\n",
        "    for i in range(num):\n",
        "        img = np.random.randint(0, 256, (128,128,3), dtype=np.uint8)\n",
        "        Image.fromarray(img).save(os.path.join(path, f\"img_{i}.jpg\"))\n",
        "\n",
        "for cls in classes:\n",
        "    generate_images(os.path.join(train_dir, cls), 120)\n",
        "    generate_images(os.path.join(val_dir, cls), 40)\n",
        "    generate_images(os.path.join(test_dir, cls), 40)\n",
        "\n",
        "train_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=25,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data = train_gen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(128,128),\n",
        "    batch_size=16,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_data = val_gen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(128,128),\n",
        "    batch_size=16,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_data = val_gen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(128,128),\n",
        "    batch_size=16,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "\n",
        "    layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=10,\n",
        "    validation_data=val_data,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "loss, acc = model.evaluate(test_data)\n",
        "print(\"Test Accuracy:\", acc * 100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8AOe2LvxwdZ",
        "outputId": "cce7c487-4774-4319-e75f-2f2354fe4452"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 240 images belonging to 2 classes.\n",
            "Found 80 images belonging to 2 classes.\n",
            "Found 80 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 639ms/step - accuracy: 0.4493 - loss: 0.8963 - val_accuracy: 0.5000 - val_loss: 0.7169\n",
            "Epoch 2/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 609ms/step - accuracy: 0.4930 - loss: 0.6987 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
            "Epoch 3/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 734ms/step - accuracy: 0.4329 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
            "Epoch 4/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 621ms/step - accuracy: 0.5617 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
            "Epoch 5/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 556ms/step - accuracy: 0.4624 - loss: 0.6933 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - accuracy: 0.7431 - loss: 0.6926\n",
            "Test Accuracy: 50.0 %\n"
          ]
        }
      ]
    }
  ]
}